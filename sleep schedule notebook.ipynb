{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c181bd5ed8933221c509e6ef7e5b26995307278dbea8c01629af8df266345df4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "\n",
    "# Restrict TensorFlow to only use the first GPU\n",
    "try:\n",
    "    tf_gpus = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in tf_gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load dataset, normalize and split into training and testing\"\"\"\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "augdf = pd.read_csv('augmenteddata.csv')\n",
    "df = pd.concat([df, augdf])\n",
    "\n",
    "dataset_value_counts = df['Value'].value_counts()\n",
    "print(f'Data counts: \\n{dataset_value_counts}')\n",
    "\n",
    "#Get sample dataframes of each value type\n",
    "min_available_dict = df['Value'].value_counts().to_dict()\n",
    "minimum_key, min_available = min(min_available_dict.items(), key= lambda x: x[1])\n",
    "\n",
    "\n",
    "if minimum_key in [1.0, 2.0]:\n",
    "    sample_size = min([min_available_dict.get(0.0), 2*min_available])\n",
    "else: sample_size = min_available\n",
    "\n",
    "if sample_size % 2:\n",
    "    sample_size -= 1\n",
    "\n",
    "bedEmptyDF = df.loc[df['Value'] == 0.0].sample(n= sample_size)\n",
    "babyInBedDF = df.loc[(df['Value'] == 1.0) | (df['Value'] == 2.0)].sample(n= sample_size)\n",
    "# babyInBedDF = df.loc[(df['Value'] == 1.0)].sample(n= sample_size//2)\n",
    "# babyAsleepDF = df.loc[(df['Value'] == 2.0)].sample(n= sample_size//2)\n",
    "\n",
    "#Combine and scramble\n",
    "#combinedDF = pd.concat([bedEmptyDF, babyInBedDF, babyAsleepDF])\n",
    "combinedDF = pd.concat([bedEmptyDF, babyInBedDF])\n",
    "combinedDF = combinedDF.sample(frac=1).reset_index(drop=True)\n",
    "training_data_counts = combinedDF['Value'].value_counts()\n",
    "print(f'Training data counts: \\n{training_data_counts}')\n",
    "print(f'Total: {combinedDF.index.size}')\n",
    "\n",
    "training_data = []\n",
    "for i in range(len(combinedDF.index)):\n",
    "    path = combinedDF.iloc[i]['ResizedPath']\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    value = combinedDF.iloc[i]['Value']\n",
    "    training_data.append([image, value])\n",
    "X = []\n",
    "y = []\n",
    "for feature, value in training_data:\n",
    "    X.append(feature)\n",
    "    if value in [1.0, 2.0]:\n",
    "        y.append(1)\n",
    "    elif value == 0.0:\n",
    "        y.append(0)\n",
    "\n",
    "# Create numpy array of images, normalize values between 0 and 1\n",
    "# Reshape array (-1 unknown qty images, 135 pixels high, 240 pixels long, 1 value per pixel)\n",
    "X = np.array(X)\n",
    "print(f'X Shape {X.shape}')\n",
    "X = X/255\n",
    "X = X.reshape(-1, 135, 240,1)\n",
    "\n",
    "# Create numpy array of output values (already 0 or 1)\n",
    "# Transform to categorical. Use the number of classes as the dimension for the last dense layer in the model\n",
    "y = np.array(y)\n",
    "y_cat = to_categorical(y, num_classes=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"View sample of training data\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "\n",
    "plt.figure(figsize=(25,12))\n",
    "for i in range(10):   \n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X[i], cmap = 'gray')\n",
    "    plt.title(y[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build model\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3,3), input_shape= X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "                optimizer= 'adam',\n",
    "                metrics= ['accuracy'])\n",
    "\n",
    "NAME = f'SLEEPING-MODEL-{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir= f'C:\\\\logs\\\\log{NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fit model with imagegenerator\"\"\"\n",
    "datagen = ImageDataGenerator(\n",
    "                                rotation_range= 5,\n",
    "                                #width_shift_range= .1,\n",
    "                                #height_shift_range= .1,\n",
    "                                zoom_range= 0.1, \n",
    "                                #shear_range= 0.1\n",
    "                                #brightness_range= [.95, 1.05], # Causes image to scale back to 0-255\n",
    "                            )\n",
    "epochs = 5\n",
    "\n",
    "divisible_by = [x for x in range(2,20) if X_train.shape[0] % x == 0]\n",
    "batch_size = max(divisible_by)\n",
    "print(f'Batch size: {batch_size}, {X_train.shape[0]} training images')\n",
    "\n",
    "model.fit(\n",
    "            datagen.flow(X_train, y_train, batch_size= batch_size),\n",
    "            epochs= epochs,\n",
    "            steps_per_epoch= X_train.shape[0] // batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks= [tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fit model with original images\"\"\"\n",
    "epochs = 5\n",
    "model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs= epochs,\n",
    "            validation_data=(X_test, y_test),\n",
    "            #callbacks= [tensorboard]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Save model\"\"\"\n",
    "now = int(time.time())\n",
    "model.save(f'models\\\\{now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load most recent model and make prediction on entire dataset\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.curdir\n",
    "model_name = max(os.listdir('models'))\n",
    "#model_name = '1615868331'\n",
    "model_path = os.path.join(current_dir, 'models', model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "testDF = pd.read_csv('data.csv')\n",
    "\n",
    "validation_list = []\n",
    "for i in range(len(testDF.index)):\n",
    "    path = testDF.iloc[i]['ResizedPath']\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    validation_list.append(image)\n",
    "\n",
    "V = np.array(validation_list)\n",
    "V = V/255\n",
    "V = V.reshape(-1,135,240,1)\n",
    "\n",
    "validation_results = model.predict(V)\n",
    "resultsDF = pd.DataFrame(validation_results, columns= ['LikelyEmpty', 'LikelyBaby'])\n",
    "\n",
    "testDF = pd.concat([testDF, resultsDF], axis=1)\n",
    "\n",
    "testDF['Value'] = testDF.apply(lambda row: 'Baby' if row.Value else 'No Baby', axis=1)\n",
    "testDF['Prediction'] = testDF.apply(lambda row: 'Baby' if row.LikelyBaby > row.LikelyEmpty else 'No Baby', axis=1)\n",
    "testDF['Incorrect'] = testDF.apply(lambda row: 1 if row.Value != row.Prediction else 0, axis=1)\n",
    "\n",
    "baby_total = testDF.loc[(testDF['Value'] == 'Baby')].index.size\n",
    "baby_incorrect = testDF.loc[(testDF['Value'] == 'Baby') & (testDF['Incorrect'] == 1)].index.size\n",
    "baby_incorrect_per = round(100 * baby_incorrect / baby_total, 2)\n",
    "baby_incorrect_str = f'{baby_incorrect} of {baby_total} images with the baby misclassified. Error rate {baby_incorrect_per}%'\n",
    "\n",
    "no_baby_total = testDF.loc[(testDF['Value'] == 'No Baby')].index.size\n",
    "no_baby_incorrect = testDF.loc[(testDF['Value'] == 'No Baby') & (testDF['Incorrect'] == 1)].index.size\n",
    "no_baby_incorrect_per = round(100 * no_baby_incorrect / no_baby_total, 2)\n",
    "no_baby_incorrect_str = f'{no_baby_incorrect} of {no_baby_total} images without baby misclassified. Error rate {no_baby_incorrect_per}%'\n",
    "\n",
    "inaccurateDF = testDF.loc[testDF['Incorrect'] == 1].reset_index()\n",
    "\n",
    "inaccurate_counts_message = f'Innacurate classifications:\\n{baby_incorrect_str}\\n{no_baby_incorrect_str}'\n",
    "print(inaccurate_counts_message)\n",
    "\n",
    "stringlist = []\n",
    "model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "shitty_string = '================================================================='\n",
    "stringlist = [line if line not in shitty_string else '======================================' for line in stringlist ]\n",
    "short_model_summary = \"\\n\".join(stringlist)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(25,12))\n",
    "\n",
    "plt.scatter(testDF['LikelyEmpty'], testDF['LikelyBaby'], alpha=.3)\n",
    "plt.scatter(inaccurateDF['LikelyEmpty'], inaccurateDF['LikelyBaby'], color='red', alpha=.3)\n",
    "plt.plot([0,1], [0,1], color='gray', lw=.5)\n",
    "plt.plot([0,1], [1,0], color='gray', lw=.5, linestyle= 'dotted')\n",
    "plt.xlabel('Likely Empty')\n",
    "plt.ylabel('Likely Baby')\n",
    "plt.title(f'Model {model_name}')\n",
    "plt.text(-.04,-.03,short_model_summary, fontsize= 8)\n",
    "plt.text(0.2,-.03,inaccurate_counts_message, fontsize= 8)\n",
    "plt.savefig(f'{model_path}\\\\{model_name}graph.png', facecolor=(1,1,1,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaccurateDF.iloc[0]['FilePath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(inaccurateDF.index)):\n",
    "    img_large = cv2.imread(inaccurateDF.at[i, 'FilePath'])\n",
    "    img_small = cv2.imread(inaccurateDF.at[i, 'ResizedPath'])\n",
    "    value = inaccurateDF.at[i, 'Value']\n",
    "    prediction = inaccurateDF.at[i, 'Prediction']\n",
    "    raw_prediction = [inaccurateDF.at[i, 'LikelyEmpty'], inaccurateDF.at[i, 'LikelyBaby']]\n",
    "\n",
    "    cv2.putText(img = img_large,\n",
    "                text = f'Value: {value}   Prediction: {prediction}   Raw: {raw_prediction}',\n",
    "                org = (0, 100),\n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale = 1,\n",
    "                color = (255, 255, 255),\n",
    "                thickness = 2)\n",
    "\n",
    "    cv2.imshow('Large', img_large)\n",
    "    cv2.imshow('Small', img_small)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Display items output from generator\"\"\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                                rotation_range= 3,\n",
    "                                width_shift_range= .05,\n",
    "                                height_shift_range= .05,\n",
    "                                zoom_range= 0.2, \n",
    "                                shear_range= 0.1\n",
    "                                #brightness_range= [.95, 1.05], # Causes image to scale back to 0-255\n",
    "                            )\n",
    "\n",
    "plt.figure(figsize=(25,12))\n",
    "for i in range(10):\n",
    "    img, value = datagen.flow(Xaug, yaug, batch_size=1).next()\n",
    "    img = img.reshape(135, 240,1)\n",
    "    img = img*255\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.title(value[0])\n",
    "    plt.imshow(img.astype('uint8'), cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate augmented copies of all photos and save to file\"\"\"\n",
    "\n",
    "datatoaugDF = pd.read_csv('data.csv')\n",
    "Xaug = []\n",
    "yaug = []\n",
    "for i in range(len(datatoaugDF.index)):\n",
    "    path = datatoaugDF.iloc[i]['ResizedPath']\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    value = datatoaugDF.iloc[i]['Value']\n",
    "    Xaug.append(image)\n",
    "    yaug.append(value)\n",
    "\n",
    "Xaug = np.array(Xaug)\n",
    "print(f'Xaug Shape {Xaug.shape}')\n",
    "Xaug = Xaug/255\n",
    "Xaug = Xaug.reshape(-1, 135, 240,1)\n",
    "\n",
    "# Create numpy array of output values (already 0 or 1)\n",
    "# Transform to categorical. Use the number of classes as the dimension for the last dense layer in the model\n",
    "yaug = np.array(yaug)\n",
    "\n",
    "\n",
    "import csv\n",
    "import os\n",
    "OUTPUT_DIRECTORY_AUGMENTED = 'C:\\\\Users\\\\parki\\\\Documents\\\\GitHub\\\\Python-Practice\\\\Sleep Schedule\\\\Training Data\\\\Augmented'\n",
    "\n",
    "#Clear existing augmented files\n",
    "files_list = [os.path.join(OUTPUT_DIRECTORY_AUGMENTED, file) for file in os.listdir(OUTPUT_DIRECTORY_AUGMENTED)]\n",
    "for file in files_list:\n",
    "    os.remove(file)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                                rotation_range= 3,\n",
    "                                width_shift_range= .05,\n",
    "                                height_shift_range= .05,\n",
    "                                zoom_range= 0.2, \n",
    "                                shear_range= 0.1\n",
    "                                #brightness_range= [.95, 1.05], # Causes image to scale back to 0-255\n",
    "                            )\n",
    "\n",
    "with open('augmenteddata.csv', 'w', newline='') as f:\n",
    "    csv.writer(f).writerow(['FilePath','ResizedPath','Value'])\n",
    "    \n",
    "    for i in range(datatoaugDF.index.size):\n",
    "        img, value = datagen.flow(Xaug, yaug, batch_size=1).next()\n",
    "        img = img.reshape(135, 240,1)\n",
    "        img = img*255\n",
    "        value = value[0]\n",
    "\n",
    "        filename = f'augmented{i+1}.png'\n",
    "        filepath = f'{OUTPUT_DIRECTORY_AUGMENTED}\\\\{filename}'\n",
    "        cv2.imwrite(filepath, img)\n",
    "        csv.writer(f).writerow(['', filepath, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIRECTORY_AUGMENTED = 'C:\\\\Users\\\\parki\\\\Documents\\\\GitHub\\\\Python-Practice\\\\Sleep Schedule\\\\Training Data\\\\Augmented'\n",
    "\n",
    "files_list = [os.path.join(OUTPUT_DIRECTORY_AUGMENTED, file) for file in os.listdir(OUTPUT_DIRECTORY_AUGMENTED)]\n",
    "for file in files_list:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}